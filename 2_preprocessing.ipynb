{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1938fbd4",
   "metadata": {},
   "source": [
    "# üßπ 2. Preprocessing Data\n",
    "\n",
    "Notebook ini akan membersihkan dan mempersiapkan data review untuk analisis sentimen.\n",
    "\n",
    "**Proses:**\n",
    "1. Load data dari `data/raw/`\n",
    "2. Cleaning teks (URL, emoji, punctuation berlebih, dll)\n",
    "3. Normalisasi slang bahasa Indonesia\n",
    "4. Labeling otomatis berdasarkan rating\n",
    "5. Simpan data bersih ke `data/interim/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc7bd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Buat folder jika belum ada\n",
    "Path('data/interim').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce8bc88",
   "metadata": {},
   "source": [
    "## Fungsi Text Cleaning\n",
    "\n",
    "Fungsi untuk membersihkan teks bahasa Indonesia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771a9463",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Membersihkan teks bahasa Indonesia.\n",
    "    \n",
    "    Proses:\n",
    "    - Lowercase\n",
    "    - Remove URL\n",
    "    - Remove email\n",
    "    - Remove mention (@)\n",
    "    - Remove hashtag (#)\n",
    "    - Remove emoji\n",
    "    - Remove punctuation berlebih (!!!, ???)\n",
    "    - Remove extra whitespace\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str) or not text:\n",
    "        return \"\"\n",
    "    \n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove URL\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
    "    \n",
    "    # Remove email\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    \n",
    "    # Remove mention\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    \n",
    "    # Remove hashtag (tapi keep kata)\n",
    "    text = re.sub(r'#(\\w+)', r'\\1', text)\n",
    "    \n",
    "    # Remove emoji (basic)\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags\n",
    "        \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub('', text)\n",
    "    \n",
    "    # Remove excessive punctuation\n",
    "    text = re.sub(r'([!?.]){2,}', r'\\1', text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Test fungsi\n",
    "test_text = \"APLIKASI @gojek SANGAT BAGUS!!! Cek https://example.com üòä\"\n",
    "print(\"Original:\", test_text)\n",
    "print(\"Cleaned:\", clean_text(test_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed76e69",
   "metadata": {},
   "source": [
    "## Normalisasi Slang Indonesia\n",
    "\n",
    "Mengubah slang/singkatan menjadi kata baku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9205a773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary slang Indonesia\n",
    "SLANG_DICT = {\n",
    "    'gak': 'tidak', 'ga': 'tidak', 'nggak': 'tidak', 'ngga': 'tidak',\n",
    "    'gk': 'tidak', 'tdk': 'tidak',\n",
    "    'udah': 'sudah', 'udh': 'sudah',\n",
    "    'blm': 'belum', 'blum': 'belum',\n",
    "    'tp': 'tapi', 'tp': 'tapi',\n",
    "    'yg': 'yang', 'dgn': 'dengan', 'utk': 'untuk',\n",
    "    'krn': 'karena', 'krna': 'karena',\n",
    "    'bgt': 'banget', 'bngdt': 'banget',\n",
    "    'bg': 'bagus', 'bgs': 'bagus',\n",
    "    'aja': 'saja',\n",
    "    'hrs': 'harus',\n",
    "    'trs': 'terus',\n",
    "    'org': 'orang',\n",
    "    'jg': 'juga', 'jgn': 'jangan',\n",
    "    'gmn': 'gimana', 'gmana': 'gimana',\n",
    "    'emg': 'memang', 'emng': 'memang',\n",
    "    'skrg': 'sekarang', 'skrng': 'sekarang',\n",
    "    'smua': 'semua'\n",
    "}\n",
    "\n",
    "def normalize_slang(text):\n",
    "    \"\"\"Normalisasi slang Indonesia.\"\"\"\n",
    "    words = text.split()\n",
    "    normalized = [SLANG_DICT.get(word, word) for word in words]\n",
    "    return ' '.join(normalized)\n",
    "\n",
    "# Test fungsi\n",
    "test_text = \"aplikasi sangat bagus bgt tp kadang error jg\"\n",
    "print(\"Original:\", test_text)\n",
    "print(\"Normalized:\", normalize_slang(test_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fc6264",
   "metadata": {},
   "source": [
    "## Auto-Labeling\n",
    "\n",
    "Labeling otomatis berdasarkan rating:\n",
    "- **1-2 stars** ‚Üí negatif\n",
    "- **3 stars** ‚Üí netral\n",
    "- **4-5 stars** ‚Üí positif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd98b8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_label(score):\n",
    "    \"\"\"\n",
    "    Label sentimen berdasarkan rating.\n",
    "    \n",
    "    Args:\n",
    "        score: Rating (1-5)\n",
    "    \n",
    "    Returns:\n",
    "        'positif', 'netral', atau 'negatif'\n",
    "    \"\"\"\n",
    "    if score >= 4:\n",
    "        return 'positif'\n",
    "    elif score == 3:\n",
    "        return 'netral'\n",
    "    else:\n",
    "        return 'negatif'\n",
    "\n",
    "# Test fungsi\n",
    "for score in [1, 2, 3, 4, 5]:\n",
    "    print(f\"Score {score} ‚Üí {auto_label(score)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169f8ef1",
   "metadata": {},
   "source": [
    "## Load & Preprocess Data\n",
    "\n",
    "Load semua file dari `data/raw/` dan proses satu per satu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c8d585",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# Cari semua file CSV di data/raw/\n",
    "raw_files = glob('data/raw/*_reviews.csv')\n",
    "\n",
    "if not raw_files:\n",
    "    print(\"‚ùå Tidak ada file di data/raw/\")\n",
    "    print(\"‚ö†Ô∏è Jalankan notebook 1_scraping.ipynb terlebih dahulu!\")\n",
    "else:\n",
    "    print(f\"üìÅ Ditemukan {len(raw_files)} file:\")\n",
    "    for f in raw_files:\n",
    "        print(f\"   - {os.path.basename(f)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a988f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataframe(df, app_name):\n",
    "    \"\"\"\n",
    "    Preprocess DataFrame.\n",
    "    \n",
    "    Proses:\n",
    "    1. Drop missing values\n",
    "    2. Clean text\n",
    "    3. Normalize slang\n",
    "    4. Auto-label\n",
    "    5. Remove duplicates\n",
    "    6. Remove very short texts\n",
    "    \"\"\"\n",
    "    print(f\"\\nüîÑ Processing {app_name}...\")\n",
    "    print(f\"   Initial rows: {len(df)}\")\n",
    "    \n",
    "    # Drop missing\n",
    "    df = df.dropna(subset=['content', 'score'])\n",
    "    print(f\"   After drop NaN: {len(df)}\")\n",
    "    \n",
    "    # Clean text\n",
    "    df['clean_text'] = df['content'].apply(clean_text)\n",
    "    \n",
    "    # Normalize slang\n",
    "    df['clean_text'] = df['clean_text'].apply(normalize_slang)\n",
    "    \n",
    "    # Remove very short texts (< 5 characters)\n",
    "    df = df[df['clean_text'].str.len() >= 5]\n",
    "    print(f\"   After remove short: {len(df)}\")\n",
    "    \n",
    "    # Auto-label\n",
    "    df['label'] = df['score'].apply(auto_label)\n",
    "    \n",
    "    # Remove duplicates\n",
    "    df = df.drop_duplicates(subset=['clean_text'], keep='first')\n",
    "    print(f\"   After dedup: {len(df)}\")\n",
    "    \n",
    "    # Show label distribution\n",
    "    print(f\"   Label distribution:\")\n",
    "    for label, count in df['label'].value_counts().items():\n",
    "        percentage = count / len(df) * 100\n",
    "        print(f\"      {label}: {count} ({percentage:.1f}%)\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2a09b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proses semua file\n",
    "all_clean_data = []\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üöÄ MULAI PREPROCESSING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for file_path in raw_files:\n",
    "    # Load data\n",
    "    app_name = os.path.basename(file_path).replace('_reviews.csv', '')\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Preprocess\n",
    "    df_clean = preprocess_dataframe(df, app_name)\n",
    "    \n",
    "    # Simpan per app\n",
    "    output_file = f'data/interim/{app_name}_clean.csv'\n",
    "    df_clean.to_csv(output_file, index=False, encoding='utf-8')\n",
    "    print(f\"   ‚úÖ Saved to: {output_file}\")\n",
    "    \n",
    "    all_clean_data.append(df_clean)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ PREPROCESSING SELESAI!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddeb395f",
   "metadata": {},
   "source": [
    "## Gabungkan Semua Data\n",
    "\n",
    "Gabungkan data dari semua aplikasi menjadi satu file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3b9122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gabungkan semua data\n",
    "df_all = pd.concat(all_clean_data, ignore_index=True)\n",
    "\n",
    "print(f\"\\nüìä Total data setelah digabung: {len(df_all)}\")\n",
    "\n",
    "# Overall label distribution\n",
    "print(f\"\\nüìà Distribusi Label Keseluruhan:\")\n",
    "label_counts = df_all['label'].value_counts()\n",
    "for label, count in label_counts.items():\n",
    "    percentage = count / len(df_all) * 100\n",
    "    print(f\"   {label}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "# Distribusi per app\n",
    "print(f\"\\nüì± Distribusi per Aplikasi:\")\n",
    "for app in df_all['app'].unique():\n",
    "    count = len(df_all[df_all['app'] == app])\n",
    "    percentage = count / len(df_all) * 100\n",
    "    print(f\"   {app}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "# Simpan gabungan\n",
    "output_all = 'data/interim/all_apps_clean.csv'\n",
    "df_all.to_csv(output_all, index=False, encoding='utf-8')\n",
    "print(f\"\\nüíæ Saved combined data to: {output_all}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e5297a",
   "metadata": {},
   "source": [
    "## Preview Data Bersih\n",
    "\n",
    "Lihat contoh data yang sudah dibersihkan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460baa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tampilkan contoh per label\n",
    "print(\"üìã CONTOH DATA PER LABEL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for label in ['positif', 'netral', 'negatif']:\n",
    "    print(f\"\\nüè∑Ô∏è {label.upper()}:\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    samples = df_all[df_all['label'] == label].head(3)\n",
    "    for idx, row in samples.iterrows():\n",
    "        print(f\"App: {row['app']} | Score: {row['score']}\")\n",
    "        print(f\"Original: {row['content'][:100]}...\")\n",
    "        print(f\"Cleaned: {row['clean_text'][:100]}...\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085ebabf",
   "metadata": {},
   "source": [
    "## üéâ Selesai!\n",
    "\n",
    "Data berhasil dibersihkan dan disimpan di `data/interim/`.\n",
    "\n",
    "**Output files:**\n",
    "- `data/interim/gojek_clean.csv`\n",
    "- `data/interim/grab_clean.csv`\n",
    "- `data/interim/maxim_clean.csv`\n",
    "- `data/interim/all_apps_clean.csv` *(gabungan semua)*\n",
    "\n",
    "**Next steps:**\n",
    "- Jalankan notebook `3_sentiment_analysis.ipynb` untuk prediksi sentimen dengan IndoBERT\n",
    "\n",
    "**Statistik:**\n",
    "- Total data: {len(df_all)} reviews\n",
    "- Label: positif, netral, negatif\n",
    "- Siap untuk analisis sentimen!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
